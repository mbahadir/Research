{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bahad\\anaconda3\\envs\\r-tutorial\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "rossman=pd.read_csv(\"D:/Datasets/Rossmann_Data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rossman[\"Date\"]=pd.to_datetime(rossman[\"Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1017209 entries, 0 to 1017208\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count    Dtype         \n",
      "---  ------         --------------    -----         \n",
      " 0   Store          1017209 non-null  int64         \n",
      " 1   DayOfWeek      1017209 non-null  int64         \n",
      " 2   Date           1017209 non-null  datetime64[ns]\n",
      " 3   Sales          1017209 non-null  int64         \n",
      " 4   Customers      1017209 non-null  int64         \n",
      " 5   Open           1017209 non-null  int64         \n",
      " 6   Promo          1017209 non-null  int64         \n",
      " 7   StateHoliday   1017209 non-null  object        \n",
      " 8   SchoolHoliday  1017209 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(7), object(1)\n",
      "memory usage: 69.8+ MB\n"
     ]
    }
   ],
   "source": [
    "rossman.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rossman.Store.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>5263</td>\n",
       "      <td>555</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>6064</td>\n",
       "      <td>625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>8314</td>\n",
       "      <td>821</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>13995</td>\n",
       "      <td>1498</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>4822</td>\n",
       "      <td>559</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  DayOfWeek       Date  Sales  Customers  Open  Promo StateHoliday  \\\n",
       "0      1          5 2015-07-31   5263        555     1      1            0   \n",
       "1      2          5 2015-07-31   6064        625     1      1            0   \n",
       "2      3          5 2015-07-31   8314        821     1      1            0   \n",
       "3      4          5 2015-07-31  13995       1498     1      1            0   \n",
       "4      5          5 2015-07-31   4822        559     1      1            0   \n",
       "\n",
       "   SchoolHoliday  \n",
       "0              1  \n",
       "1              1  \n",
       "2              1  \n",
       "3              1  \n",
       "4              1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rossman.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_encoder=OneHotEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State Holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    855087\n",
       "0    131072\n",
       "a     20260\n",
       "b      6690\n",
       "c      4100\n",
       "Name: StateHoliday, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rossman[\"StateHoliday\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rossman[\"StateHoliday\"]=rossman[\"StateHoliday\"].astype(str)\n",
    "encoded_stateholidays=hot_encoder.fit_transform(rossman[[\"StateHoliday\"]])\n",
    "array_stateholidays=encoded_stateholidays.toarray()\n",
    "state_df=pd.DataFrame(array_stateholidays,columns=[\"0\", \"A\", \"B\", \"C\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    A    B    C  \n",
       "1.0  0.0  0.0  0.0    986159\n",
       "0.0  1.0  0.0  0.0     20260\n",
       "     0.0  1.0  0.0      6690\n",
       "          0.0  1.0      4100\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_df.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weekdays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    145845\n",
       "4    145845\n",
       "3    145665\n",
       "2    145664\n",
       "7    144730\n",
       "6    144730\n",
       "1    144730\n",
       "Name: DayOfWeek, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rossman[\"DayOfWeek\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_weekdays=hot_encoder.fit_transform(rossman[[\"DayOfWeek\"]])\n",
    "array_weekdays=encoded_weekdays.toarray()\n",
    "weekday_df=pd.DataFrame(array_weekdays,columns=[\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\",\"Friday\",\"Saturday\",\"Sunday\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Monday  Tuesday  Wednesday  Thursday  Friday  Saturday  Sunday\n",
       "0.0     0.0      0.0        1.0       0.0     0.0       0.0       145845\n",
       "                            0.0       1.0     0.0       0.0       145845\n",
       "                 1.0        0.0       0.0     0.0       0.0       145665\n",
       "        1.0      0.0        0.0       0.0     0.0       0.0       145664\n",
       "1.0     0.0      0.0        0.0       0.0     0.0       0.0       144730\n",
       "0.0     0.0      0.0        0.0       0.0     1.0       0.0       144730\n",
       "                                              0.0       1.0       144730\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekday_df.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenated dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [rossman, state_df, weekday_df]\n",
    "rossman_concat=pd.concat(frames, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <th>0</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>Monday</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>Wednesday</th>\n",
       "      <th>Thursday</th>\n",
       "      <th>Friday</th>\n",
       "      <th>Saturday</th>\n",
       "      <th>Sunday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.017209e+06</td>\n",
       "      <td>1.017209e+06</td>\n",
       "      <td>1.017209e+06</td>\n",
       "      <td>1.017209e+06</td>\n",
       "      <td>1.017209e+06</td>\n",
       "      <td>1.017209e+06</td>\n",
       "      <td>1.017209e+06</td>\n",
       "      <td>1.017209e+06</td>\n",
       "      <td>1.017209e+06</td>\n",
       "      <td>1.017209e+06</td>\n",
       "      <td>1.017209e+06</td>\n",
       "      <td>1.017209e+06</td>\n",
       "      <td>1.017209e+06</td>\n",
       "      <td>1.017209e+06</td>\n",
       "      <td>1.017209e+06</td>\n",
       "      <td>1.017209e+06</td>\n",
       "      <td>1.017209e+06</td>\n",
       "      <td>1.017209e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.584297e+02</td>\n",
       "      <td>3.998341e+00</td>\n",
       "      <td>5.773819e+03</td>\n",
       "      <td>6.331459e+02</td>\n",
       "      <td>8.301067e-01</td>\n",
       "      <td>3.815145e-01</td>\n",
       "      <td>1.786467e-01</td>\n",
       "      <td>9.694753e-01</td>\n",
       "      <td>1.991724e-02</td>\n",
       "      <td>6.576820e-03</td>\n",
       "      <td>4.030637e-03</td>\n",
       "      <td>1.422815e-01</td>\n",
       "      <td>1.431997e-01</td>\n",
       "      <td>1.432007e-01</td>\n",
       "      <td>1.433776e-01</td>\n",
       "      <td>1.433776e-01</td>\n",
       "      <td>1.422815e-01</td>\n",
       "      <td>1.422815e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.219087e+02</td>\n",
       "      <td>1.997391e+00</td>\n",
       "      <td>3.849926e+03</td>\n",
       "      <td>4.644117e+02</td>\n",
       "      <td>3.755392e-01</td>\n",
       "      <td>4.857586e-01</td>\n",
       "      <td>3.830564e-01</td>\n",
       "      <td>1.720261e-01</td>\n",
       "      <td>1.397160e-01</td>\n",
       "      <td>8.083051e-02</td>\n",
       "      <td>6.335925e-02</td>\n",
       "      <td>3.493388e-01</td>\n",
       "      <td>3.502765e-01</td>\n",
       "      <td>3.502775e-01</td>\n",
       "      <td>3.504577e-01</td>\n",
       "      <td>3.504577e-01</td>\n",
       "      <td>3.493388e-01</td>\n",
       "      <td>3.493388e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.800000e+02</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>3.727000e+03</td>\n",
       "      <td>4.050000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.580000e+02</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>5.744000e+03</td>\n",
       "      <td>6.090000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.380000e+02</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>7.856000e+03</td>\n",
       "      <td>8.370000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.115000e+03</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>4.155100e+04</td>\n",
       "      <td>7.388000e+03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Store     DayOfWeek         Sales     Customers          Open  \\\n",
       "count  1.017209e+06  1.017209e+06  1.017209e+06  1.017209e+06  1.017209e+06   \n",
       "mean   5.584297e+02  3.998341e+00  5.773819e+03  6.331459e+02  8.301067e-01   \n",
       "std    3.219087e+02  1.997391e+00  3.849926e+03  4.644117e+02  3.755392e-01   \n",
       "min    1.000000e+00  1.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    2.800000e+02  2.000000e+00  3.727000e+03  4.050000e+02  1.000000e+00   \n",
       "50%    5.580000e+02  4.000000e+00  5.744000e+03  6.090000e+02  1.000000e+00   \n",
       "75%    8.380000e+02  6.000000e+00  7.856000e+03  8.370000e+02  1.000000e+00   \n",
       "max    1.115000e+03  7.000000e+00  4.155100e+04  7.388000e+03  1.000000e+00   \n",
       "\n",
       "              Promo  SchoolHoliday             0             A             B  \\\n",
       "count  1.017209e+06   1.017209e+06  1.017209e+06  1.017209e+06  1.017209e+06   \n",
       "mean   3.815145e-01   1.786467e-01  9.694753e-01  1.991724e-02  6.576820e-03   \n",
       "std    4.857586e-01   3.830564e-01  1.720261e-01  1.397160e-01  8.083051e-02   \n",
       "min    0.000000e+00   0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00   0.000000e+00  1.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%    0.000000e+00   0.000000e+00  1.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%    1.000000e+00   0.000000e+00  1.000000e+00  0.000000e+00  0.000000e+00   \n",
       "max    1.000000e+00   1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "\n",
       "                  C        Monday       Tuesday     Wednesday      Thursday  \\\n",
       "count  1.017209e+06  1.017209e+06  1.017209e+06  1.017209e+06  1.017209e+06   \n",
       "mean   4.030637e-03  1.422815e-01  1.431997e-01  1.432007e-01  1.433776e-01   \n",
       "std    6.335925e-02  3.493388e-01  3.502765e-01  3.502775e-01  3.504577e-01   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "max    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "\n",
       "             Friday      Saturday        Sunday  \n",
       "count  1.017209e+06  1.017209e+06  1.017209e+06  \n",
       "mean   1.433776e-01  1.422815e-01  1.422815e-01  \n",
       "std    3.504577e-01  3.493388e-01  3.493388e-01  \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "25%    0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "50%    0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "75%    0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "max    1.000000e+00  1.000000e+00  1.000000e+00  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rossman_concat.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_list(ID,actual,forecast):\n",
    "    name=ID\n",
    "    n=len(actual)\n",
    "    error=actual-forecast\n",
    "    mean=np.mean(actual)\n",
    "    sd=actual.std()\n",
    "    FBias=sum(error)/sum(actual)\n",
    "    RMSE=np.sqrt(sum(error**2))/n\n",
    "    MAD=sum(abs(error))/n\n",
    "    WMAPE=MAD/mean\n",
    "    result_df=pd.DataFrame({\"Name\" :       name ,\n",
    "                            \"# of inst\":       n,\n",
    "                            \"Mean\":         mean,\n",
    "                            \"Standard Dev.\":  sd, \n",
    "                            \"FBias\":       FBias,                                     \n",
    "                            \"RMSE\":         RMSE, \n",
    "                            \"MAD\":           MAD, \n",
    "                            \"WMAPE\":      WMAPE}, index=[0])\n",
    "    return(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store and Dataset Selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_selection(dataset, store_num):\n",
    "    selected_store=dataset[dataset[\"Store\"]==store_num].copy()\n",
    "    selected_store.sort_values(by=[\"Date\"], inplace=True)\n",
    "    selected_store.reset_index(drop=True, inplace=True)\n",
    "    selected_store.head(20)\n",
    "    return selected_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Splitting_data(dataset, ratio):\n",
    "    interval=dataset.Date.max()-dataset.Date.min()\n",
    "    day_int=interval*ratio\n",
    "    Train=dataset[dataset[\"Date\"]<(dataset.Date.max()-day_int)]\n",
    "    Test=dataset[dataset[\"Date\"]>=(dataset.Date.max()-day_int)]\n",
    "    return Train, Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train & Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data=rossman_concat, index=1, perc=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitting_dataset(data, index, perc):\n",
    "    store=store_selection(data, index)\n",
    "    train1_initial, test1_initial=Splitting_data(store, perc)   \n",
    "    train=train1_initial.drop([\"Date\", \"Customers\",\"Store\",\"DayOfWeek\",\"StateHoliday\"], axis=1)\n",
    "    test=test1_initial.drop([\"Date\", \"Customers\",\"Store\",\"DayOfWeek\",\"StateHoliday\"], axis=1)\n",
    "    X_train, y_train=train.drop([\"Sales\"], axis=1), train[\"Sales\"]\n",
    "    X_test, y_test=test.drop([\"Sales\"], axis=1), test[\"Sales\"]\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test=splitting_dataset(rossman_concat, 1, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression-Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_net(X_train, y_train, X_test, y_test):\n",
    "    elastic_net_model = ElasticNet()\n",
    "    param_grid_elastic=[\n",
    "    {\"alpha\":[0.1,0.2,0.3,0.4], \"l1_ratio\":[0.2,0.4,0.6]}\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    elastic_net = GridSearchCV(estimator=elastic_net_model, param_grid=param_grid_elastic,\n",
    "                 cv=10,return_train_score=True)\n",
    "    \n",
    "    \n",
    "    elastic_net.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    elastic_predictions_train=elastic_net.predict(X_train)    \n",
    "    res_elastic_train=performance_list(\"Elastic Net Train\", y_train, elastic_predictions_train)\n",
    "    #display(res_elastic_train)\n",
    "    \n",
    "    elastic_predictions=elastic_net.predict(X_test)    \n",
    "    res_elastic=performance_list(\"Elastic Net Performance\", y_test, elastic_predictions)\n",
    "    #display(res_elastic)\n",
    "    \n",
    "    return(res_elastic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_elastic=elastic_net(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_linear(X_train, y_train, X_test, y_test):\n",
    "    sv_regressor=LinearSVR(max_iter=10000)\n",
    "    param_grid_svm_linear=[\n",
    "    {\"epsilon\":[0.5,1,1.5,2]}\n",
    "    ]\n",
    "    sv_regressor = GridSearchCV(estimator=sv_regressor, param_grid=param_grid_svm_linear,\n",
    "                 cv=10,return_train_score=True)\n",
    "    \n",
    "    sv_regressor.fit(X_train, y_train)\n",
    "    \n",
    "    svm_predictions_linear_train=sv_regressor.predict(X_train)\n",
    "    svm_predictions_linear_train=performance_list(\"Support Vector Regressor Linear Train\", y_train, svm_predictions_linear_train)\n",
    "    #display(svm_predictions_linear_train)\n",
    "    \n",
    "    svm_predictions_linear=sv_regressor.predict(X_test)\n",
    "    res_svr_linear=performance_list(\"Support Vector Regressor Linear Performance\", y_test, svm_predictions_linear)\n",
    "    #display(res_svr_linear)\n",
    "    return(res_svr_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_svr_linear=svm_linear(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poly with Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_poly(X_train, y_train, X_test, y_test):\n",
    "    sv_regressor_poly=SVR(kernel=\"poly\")\n",
    "    param_grid_svm_poly=[\n",
    "    {\"degree\":[1,2,3,4], \"epsilon\":[0.02,0.05, 0.1, 0.15, 0.2]}\n",
    "    ]\n",
    "    \n",
    "    sv_regressor_poly = GridSearchCV(estimator=sv_regressor_poly, param_grid=param_grid_svm_poly,\n",
    "                 cv=10,return_train_score=True)\n",
    "    \n",
    "    sv_regressor_poly.fit(X_train, y_train)\n",
    "    #print(sv_regressor_poly.best_estimator_)\n",
    "    \n",
    "    svm_predictions_poly_train=sv_regressor_poly.predict(X_train)\n",
    "    res_svr_poly_train=performance_list(\"Support Vector Regressor Polynomial Train\", y_train, svm_predictions_poly_train)\n",
    "    #display(res_svr_poly_train)\n",
    "    \n",
    "    svm_predictions_poly=sv_regressor_poly.predict(X_test)\n",
    "    res_svr_poly=performance_list(\"Support Vector Regressor Polynomial Performance\",y_test, svm_predictions_poly)\n",
    "    #display(res_svr_poly)\n",
    "    return(res_svr_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_svr_poly=svm_poly(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(X_train, y_train, X_test, y_test):\n",
    "    random_reg=RandomForestRegressor(max_depth=5,min_samples_leaf=5)\n",
    "    param_grid=[\n",
    "    {\"n_estimators\":[100,200,300],\n",
    "     \"bootstrap\":[False,True]}\n",
    "    ]\n",
    "    \n",
    "    grid_search = GridSearchCV(estimator=random_reg, param_grid=param_grid,\n",
    "                 cv=10,return_train_score=True)\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(grid_search.best_params_)\n",
    "    \n",
    "    rf_predictions_train=grid_search.predict(X_train)\n",
    "    res_rf_train=performance_list(\"Random Forest Performance Train\", y_train, rf_predictions_train)\n",
    "    \n",
    "    rf_predictions=grid_search.predict(X_test)\n",
    "    res_rf=performance_list(\"Random Forest Performance\",y_test, rf_predictions)\n",
    "\n",
    "    return(res_rf_train, res_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_rf_train, res_rf=random_forest(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Node Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extract(X_train, y_train, X_test, y_test):\n",
    "    grid_search = DecisionTreeRegressor()\n",
    "    param_grid_feature = [\n",
    "    {'min_samples_leaf': [5, 7, 10, 15, 20], 'max_depth': [4, 5, 7, 10, 12, 15], 'min_samples_split': [30, 40, 50, 60, 80]}\n",
    "    ]\n",
    "    \n",
    "    estimator_best = GridSearchCV(grid_search, param_grid_feature, cv=5)\n",
    "    estimator_best.fit(X_train, y_train)\n",
    "    \n",
    "    ## Best Parameters\n",
    "    estimator_best.best_estimator_\n",
    "    \n",
    "    ### Final Decision Tree\n",
    "    estimator = DecisionTreeRegressor(max_depth= estimator_best.best_estimator_.max_depth, \n",
    "                                      min_impurity_decrease= estimator_best.best_estimator_.min_impurity_decrease,\n",
    "                                      min_samples_leaf= estimator_best.best_estimator_.min_samples_leaf)\n",
    "\n",
    "    estimator.fit(X_train, y_train)\n",
    "\n",
    "    on_leaf = estimator.apply(X_train)\n",
    "    X_train_ext=X_train.copy()\n",
    "    X_train_ext[\"Node\"] = on_leaf.tolist()\n",
    "\n",
    "#     plt.figure(figsize=(14, 8)) \n",
    "#     plt.show(tree.plot_tree(estimator,filled=True, fontsize=8))\n",
    "#     display(X_train_ext)\n",
    "    \n",
    "    \n",
    "    ### Test Node Selection\n",
    "    on_leaf_test = estimator.apply(X_test)\n",
    "\n",
    "    X_test_ext=X_test.copy()\n",
    "\n",
    "    X_test_ext[\"Node\"] = on_leaf_test.tolist()\n",
    "\n",
    "    X_test_ext\n",
    "#     display(X_train_ext)\n",
    "    \n",
    "    ### Feature Adding\n",
    "\n",
    "    #Ma=1 \n",
    "\n",
    "    Xframes_feature=[X_train_ext, X_test_ext]\n",
    "    yframes_feature=[y_train, y_test]\n",
    "    X_concat=pd.concat(Xframes_feature)\n",
    "    Y_concat=pd.concat(yframes_feature)\n",
    "    final_frame=[X_concat, Y_concat]\n",
    "    concated_df=pd.concat(final_frame, axis=1)\n",
    "\n",
    "    concated_df[\"new_feature\"] = concated_df.groupby([\"Node\"])[\"Sales\"].shift(+1)\n",
    "\n",
    "    X_test_new=concated_df.iloc[len(X_train):].drop([\"Sales\",\"Node\"], axis=1)\n",
    "\n",
    "    y_test_new=concated_df.iloc[len(X_train):][\"Sales\"]\n",
    "\n",
    "    train_new=concated_df.iloc[:len(X_train)]\n",
    "\n",
    "    train_new.dropna(inplace=True);\n",
    "    train_new.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    X_train_new=train_new.drop([\"Sales\",\"Node\"], axis=1)\n",
    "\n",
    "    y_train_new=train_new[\"Sales\"]\n",
    "    \n",
    "    \n",
    "    return(X_train_new, y_train_new, X_test_new, y_test_new)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new, y_train_new, X_test_new, y_test_new=feature_extract(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_elastic_new=elastic_net(X_train_new, y_train_new, X_test_new, y_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#res_svr_new=svm_linear(X_train_new, y_train_new, X_test_new, y_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_svr_poly_new=svm_poly(X_train_new, y_train_new, X_test_new, y_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_rf_train_new, res_rf_new=random_forest(X_train_new, y_train_new, X_test_new, y_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_rf_train_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Result Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.8f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_frames=[res_elastic,res_svr_linear,res_svr_poly,res_rf, res_elastic_new,res_svr_new,res_svr_poly_new,res_rf_new]\n",
    "total_result=pd.concat(result_frames)\n",
    "total_result.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_one_store(dataset, store_id, percent):\n",
    "    X_train, y_train, X_test, y_test=splitting_dataset(dataset, store_id, percent)\n",
    "    \n",
    "    res_elastic=elastic_net(X_train, y_train, X_test, y_test)\n",
    "    #res_svr_linear=svm_linear(X_train, y_train, X_test, y_test)\n",
    "    res_svr_poly=svm_poly(X_train, y_train, X_test, y_test)\n",
    "    res_rf_train, res_rf=random_forest(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    \n",
    "    X_train_new, y_train_new, X_test_new, y_test_new=feature_extract(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    res_elastic_new=elastic_net(X_train_new, y_train_new, X_test_new, y_test_new)\n",
    "    #res_svr_new=svm_linear(X_train_new, y_train_new, X_test_new, y_test_new)\n",
    "    res_svr_poly_new=svm_poly(X_train_new, y_train_new, X_test_new, y_test_new)\n",
    "    res_rf_train_new, res_rf_new=random_forest(X_train_new, y_train_new, X_test_new, y_test_new)\n",
    "    \n",
    "    \n",
    "    result_frames=[res_elastic,res_svr_linear,res_svr_poly,res_rf, res_elastic_new,res_svr_new,res_svr_poly_new,res_rf_new]\n",
    "    total_result=pd.concat(result_frames)\n",
    "    total_result.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    display(total_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "result_one_store(rossman_concat, 2, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(concated_df.Sales[:28])\n",
    "\n",
    "# from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "# plot_acf(concated_df.Sales, lags=28)\n",
    "# plt.show()\n",
    "\n",
    "# ## Node Control\n",
    "\n",
    "# concated_df.Node.value_counts()\n",
    "\n",
    "# concated_df[concated_df[\"Node\"]==6]\n",
    "\n",
    "# concated_df[concated_df[\"Node\"]==10]\n",
    "\n",
    "# concated_df[concated_df[\"Node\"]==19]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
